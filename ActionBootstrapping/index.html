
<html>
<head>
  <title>Action Bootstrapping</title>
  <link rel="stylesheet" type="text/css" href="css/style.css">
</head>

<body> 

<div class="container">
  <h1><span style="font-size:42px">Action Bootstrapping</span></h1>
  <br>
  <table width="600px" align="center">
    <tr>
      <td align=center width=100px>
        <center>
          <span style="font-size:24px"><a href="https://gkioxari.github.io/">Ziming Liu</a></span>
        </center>
      </td>
      
  </table>
  <br>
  <table>
    <tr>
      <span style="font-size: 22px"> Beijing Institute of Tech </span>
    </tr>
    <br><br>
    <tr>
      <span style="font-size: 20px"> ACM MM 2019 </span>
    </tr>
  </table>
  <br>
  <table width="400px" align="center">
    <tr>
      <td align=center width=100px>
        <center>
          <span style="font-size:24px"><a href="https://dl.acm.org/doi/10.1145/3343031.3350916">[Paper]</a></span>
        </center>
      </td>
      <td align=center width=200px>
        <center>
          <span style="font-size:24px"><a href="">[Code]</a></span>
        </center>
      </td>
  </table>
  
  <p>
      <div class="row">
        <div class="column">
          <img src="../teasers/actionbootstrapping.png" style="width:100%; padding-top:35px;">
        </div>
        
      </div>
  </p>
</div>

</br>

<div class="container">
  <h1>Abstract</h1>
    <p align="justify">
      Actions always refer to complex vision variations in a long-range redundant video sequence. Instead of focusing on limited range sequence, i.e. convolution on adjacent frames, in this paper, we proposed an action recognition approach with bootstrapping based long-range temporal context attention. Specifically, due to vision variations of the local region across frames, we target at capturing temporal context by proposing the Temporal Pixels based Parallel-head Attention (TPPA) block. In TPPA, we apply the self-attention mechanism between local regions at the same position across temporal frames to capture the interaction impacts. Meanwhile, to deal with video redundancy and capture long-range context, the TPPA is extended to the Random Frames based Bootstrapping Attention (RFBA) framework. While the bootstrapping sampling frames have the same distribution of the whole video sequence, the RFBA not only captures longer temporal context with only a few sampling frames but also has comprehensive representation through multiple sampling. Furthermore, we also try to apply this temporal context attention to image-based action recognition, by transforming the image into "pseudo video" with the spatial shift. Finally, we conduct extensive experiments and empirical evaluations on two most popular datasets:UCF101 for videos andStanford40 for images. In particular, our approach achieves top-1 accuracy of $91.7%$ in UCF101 and mAP of $90.9%$ in Stanford40.    </p> 
</div>   

</br>

<div class="container">
  <h1>Approach</h1>
    <p><img src="resources/overall.png" height="300" align="middle" /></p>
</div>   

</br>

<div class="container">
  <h1> Paper</h1>
  <table align=center width=600px height=250px>
  <tr>
    <td align=left width=300px><a href="https://dl.acm.org/doi/10.1145/3343031.3350916"><img class="layered-paper-big" style="height:180px" src="./resources/paper_preview.png"/></a></td>
    <td align=center width=500px style="color: #4d4b59; font-size:14pt">Ziming Liu, Guangyu Gao, A. K. Qin, Tong Wu.<br><br>
                Action Bootstrapping.<br><br>
                In ACM MM 2019.<br><br>
                <span style="font-size:20px"><a href="resources/bibtex.txt">[bibtex]</a></span>
    </td>
  </tr>
  </table>
</div>

</br>

<div class="container">
  <h1>Acknowledgements</h1>
    <p align="justify">
      This work was supported by the National Natural Science Foundation of China under Grant No.U1736117,and in part by the Australian Research Council with Grant No. LP170100416 and LP180100114.
    </p>
</div>   

</br>

<div class="containersmall">
  <p>Contact: <a href="mailto:liuziming.email@gmail.com">Zi-Ming Liu</a></p>
</div>
 
<!--<p align="center" class="acknowledgement">Last updated: 30 July 2012</p>-->
</body>
</html>
